{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd5077d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, Flatten, Dense, Softmax, BatchNormalization, Dropout, Add\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d54d124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666d92a",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **play_style_train.csv** file and split the games into a list.\n",
    "Every row of csv: `PSL0000000001,1,B[pd],W[dp],B[qp],W[dc],B[nq],W[nc],B[qf],W[kd],B[ce],W[dg],B[dd],W[cc],B[fd],W[ed],B[ee],W[ec],B[ge],W[gc],B[di]`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. PSL0000000001: Game ID\n",
    "    2. 1: Game Style\n",
    "    3-... : Moves, the last move represents the play style (B[di] in this case)\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4b559ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('./CSVs/Tutorial_play_style_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]\n",
    "game_styles = [int(i.split(',',2)[-2]) for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f64af3",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b52349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3429687",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 2 dimensional feature map to represent the data as below:\n",
    " 1. Occupied areas: mark them as 1 and the empty places as 0\n",
    " 2. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "The target is to predict the game style (1, 2 or 3) from the state of the game table. Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b28ab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves):\n",
    "    x = np.zeros((19,19,2))\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        x[row,column,0] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,1] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1a544a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 1145\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "print(f\"Total Games: {n_games}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30773a",
   "metadata": {},
   "source": [
    "Since play style training has smaller dataset comparing to kyu or dan training, we can put the complete dataset to memory. Still, it is better to create a data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40cce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for game in games:\n",
    "    moves_list = game.split(',')\n",
    "    x.append(prepare_input(moves_list))\n",
    "x = np.array(x)\n",
    "y = np.array(game_styles)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74d9b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1145, 19, 19, 2)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ad8b3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1145,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f20561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([268, 530, 347])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c86e70",
   "metadata": {},
   "source": [
    "Target is one-hot encoded and loss is changed to `categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54f30621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hot = tf.one_hot(y, depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae1a16",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b80a8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y_hot.numpy(), test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8964d8",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad6d4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 2))\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(inputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=7, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)  \n",
    "    outputs = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Flatten()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(32, activation='relu')(outputs)\n",
    "    outputs = BatchNormalization()(outputs)\n",
    "    outputs = Dense(3, activation='softmax', )(outputs)\n",
    "    model = Model(inputs, outputs)\n",
    "    opt = Adam(learning_rate=0.00005)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameSimulator:\n",
    "    def __init__(self):\n",
    "        # 初始游戏状态，你可以根据你的游戏规则初始化棋盘或游戏状态\n",
    "        self.board = [[' ' for _ in range(19)] for _ in range(19)]  # 例如，这里创建一个19x19的空棋盘\n",
    "    \n",
    "    def reset(self):\n",
    "        # 重置游戏状态为初始状态\n",
    "        self.board = [[' ' for _ in range(19)] for _ in range(19)]  # 重新创建一个空棋盘作为初始状态\n",
    "        return self.board  # 返回初始状态的游戏棋盘\n",
    "    \n",
    "    def get_legal_moves(self):\n",
    "        legal_moves = []\n",
    "        for i in range(19):\n",
    "            for j in range(19):\n",
    "                if self.board[i][j] == ' ':\n",
    "                    legal_moves.append((i, j))  # 如果位置为空，表示合法的移动\n",
    "        return legal_moves\n",
    "\n",
    "    def make_move(self, move, player):\n",
    "        row, col = move\n",
    "        if self.board[row][col] == ' ':\n",
    "            self.board[row][col] = player  # 将空位置设为玩家的标记，例如 'B' 或 'W'\n",
    "            return True  # 返回 True 表示移动成功\n",
    "        else:\n",
    "            return False  # 返回 False 表示移动无效，位置已经被占用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "295280dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 19, 19, 2)]       0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 19, 19, 32)        3168      \n",
      "                                                                 \n",
      " batch_normalization_82 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 19, 19, 32)        50208     \n",
      "                                                                 \n",
      " batch_normalization_83 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 19, 19, 32)        25632     \n",
      "                                                                 \n",
      " batch_normalization_84 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 19, 19, 32)        25632     \n",
      "                                                                 \n",
      " batch_normalization_85 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_86 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_87 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 19, 19, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_88 (Ba  (None, 19, 19, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 23104)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 32)                739360    \n",
      "                                                                 \n",
      " batch_normalization_89 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_90 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 883427 (3.37 MB)\n",
      "Trainable params: 882787 (3.37 MB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c826c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0895 - accuracy: 0.9864 - val_loss: 1.0823 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0959 - accuracy: 0.9883 - val_loss: 1.1796 - val_accuracy: 0.6174\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0651 - accuracy: 0.9951 - val_loss: 1.1994 - val_accuracy: 0.6174\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0600 - accuracy: 0.9942 - val_loss: 1.2057 - val_accuracy: 0.6174\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0565 - accuracy: 0.9961 - val_loss: 1.2393 - val_accuracy: 0.6087\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0577 - accuracy: 0.9942 - val_loss: 1.2093 - val_accuracy: 0.6522\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0555 - accuracy: 0.9942 - val_loss: 1.2178 - val_accuracy: 0.6435\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0520 - accuracy: 0.9971 - val_loss: 1.1911 - val_accuracy: 0.5826\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0506 - accuracy: 0.9971 - val_loss: 1.2040 - val_accuracy: 0.5913\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0441 - accuracy: 0.9971 - val_loss: 1.2261 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0463 - accuracy: 0.9961 - val_loss: 1.2404 - val_accuracy: 0.5826\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0473 - accuracy: 0.9951 - val_loss: 1.2361 - val_accuracy: 0.6000\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0458 - accuracy: 0.9961 - val_loss: 1.2481 - val_accuracy: 0.5913\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0613 - accuracy: 0.9922 - val_loss: 1.2748 - val_accuracy: 0.5739\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 1s 34ms/step - loss: 0.0575 - accuracy: 0.9951 - val_loss: 1.2305 - val_accuracy: 0.5652\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0403 - accuracy: 0.9971 - val_loss: 1.2354 - val_accuracy: 0.5652\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0391 - accuracy: 0.9971 - val_loss: 1.2313 - val_accuracy: 0.5565\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0356 - accuracy: 0.9981 - val_loss: 1.2140 - val_accuracy: 0.5826\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0354 - accuracy: 0.9981 - val_loss: 1.2210 - val_accuracy: 0.5826\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.0326 - accuracy: 0.9981 - val_loss: 1.2173 - val_accuracy: 0.5913\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train, \n",
    "    y = y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 20,\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ed0f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ttsai/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('./model_playstyle.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58388eb",
   "metadata": {},
   "source": [
    "## ALL DONE!\n",
    "\n",
    "For using the model and creating a submission file, follow the notebook **Create Public Upload CSV.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436139c",
   "metadata": {},
   "source": [
    "# End of Tutorial\n",
    "\n",
    "You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc41e067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
