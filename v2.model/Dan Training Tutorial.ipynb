{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb173248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 02:43:00.545340: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-09 02:43:00.567479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-09 02:43:00.567502: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-09 02:43:00.568052: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-09 02:43:00.571744: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 02:43:01.003869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, concatenate\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62384345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd95ed0c",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "Open **dan_train.csv** file and split the games into a list.\n",
    "Every row of csv: `DL0000000001,B,B[pd],W[dp],B[pp],W[dc],B[de],...`. \n",
    "\n",
    "Columns are:\n",
    "\n",
    "    1. DL0000000001: Game ID\n",
    "    2. B: Player's color\n",
    "    3-... : Moves\n",
    "    \n",
    "We cropped only the moves to game list as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8872fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open('/home/ttsai/DL/AIcupTutorial-main/Training Dataset/Tutorial_dan_train.csv').read().splitlines()\n",
    "games = [i.split(',',2)[-1] for i in df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58532b01",
   "metadata": {},
   "source": [
    "Create a dictionary to convert the coordinates from characters to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "496585f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'b': 1,\n",
       " 'c': 2,\n",
       " 'd': 3,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'g': 6,\n",
       " 'h': 7,\n",
       " 'i': 8,\n",
       " 'j': 9,\n",
       " 'k': 10,\n",
       " 'l': 11,\n",
       " 'm': 12,\n",
       " 'n': 13,\n",
       " 'o': 14,\n",
       " 'p': 15,\n",
       " 'q': 16,\n",
       " 'r': 17,\n",
       " 's': 18}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = 'abcdefghijklmnopqrs'\n",
    "coordinates = {k:v for v,k in enumerate(chars)}\n",
    "chartonumbers = {k:v for k,v in enumerate(chars)}\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92277370",
   "metadata": {},
   "source": [
    "We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n",
    "\n",
    "For the simplicity, we used 4 dimensional feature map to represent the data as below:\n",
    " 1. Positions of black stones: mark them as 1 and the rest of the table as 0\n",
    " 2. Positions of white stones: mark them as 1 and the rest of the table as 0\n",
    " 3. Empty areas of the table: mark the empty areas as 1 and occupied areas as 0\n",
    " 4. The last move in the table: mark the position of the last move as 1 and the rest as 0\n",
    " \n",
    "Target value is a number between 0-361(19\\*19). Later this will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0adb423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves,board):\n",
    "    x = np.zeros((19,19,4))\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row,column,0] = 1\n",
    "            x[row,column,2] = 1\n",
    "        if color == 'W':\n",
    "            x[row,column,1] = 1\n",
    "            x[row,column,2] = 1\n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[row,column,3] = 1\n",
    "    x[:,:,2] = np.where(x[:,:,2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column*19+row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "973436ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(moves, board):\n",
    "    x = np.zeros((19, 19, 6))  # 增加了兩個額外的特徵\n",
    "    for move in moves:\n",
    "        color = move[0]\n",
    "        column = coordinates[move[2]]\n",
    "        row = coordinates[move[3]]\n",
    "        if color == 'B':\n",
    "            x[row, column, 0] = 1\n",
    "            x[row, column, 2] = 1\n",
    "        if color == 'W':\n",
    "            x[row, column, 1] = 1\n",
    "            x[row, column, 2] = 1\n",
    "    \n",
    "    if moves:\n",
    "        last_move_column = coordinates[moves[-1][2]]\n",
    "        last_move_row = coordinates[moves[-1][3]]\n",
    "        x[last_move_row, last_move_column, 3] = 1\n",
    "    \n",
    "    # 新增特徵：黑棋下一步可能被包圍的位置為 1\n",
    "    for i in range(19):\n",
    "        for j in range(19):\n",
    "            if is_surrounded(x, i, j, 'B'):\n",
    "                x[i, j, 4] = 1\n",
    "    \n",
    "    # 新增特徵：白棋下一步可能被包圍的位置為 1\n",
    "    for i in range(19):\n",
    "        for j in range(19):\n",
    "            if is_surrounded(x, i, j, 'W'):\n",
    "                x[i, j, 5] = 1\n",
    "    \n",
    "    x[:, :, 2] = np.where(x[:, :, 2] == 0, 1, 0)\n",
    "    return x\n",
    "\n",
    "# 新增一個輔助函數用來檢查是否某顏色的棋子可能被包圍\n",
    "def is_surrounded(board, row, col, color):\n",
    "    # 檢查垂直連線是否有兩個以上的相同顏色棋子\n",
    "    vertical_count = 0\n",
    "    for i in range(max(0, row - 1), min(18, row + 2)):\n",
    "        if board[i, col, 0 if color == 'B' else 1] == 1:\n",
    "            vertical_count += 1\n",
    "    if vertical_count >= 2:\n",
    "        return True\n",
    "    \n",
    "    # 檢查水平連線是否有兩個以上的相同顏色棋子\n",
    "    horizontal_count = 0\n",
    "    for j in range(max(0, col - 1), min(18, col + 2)):\n",
    "        if board[row, j, 0 if color == 'B' else 1] == 1:\n",
    "            horizontal_count += 1\n",
    "    if horizontal_count >= 2:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def prepare_label(move):\n",
    "    column = coordinates[move[2]]\n",
    "    row = coordinates[move[3]]\n",
    "    return column * 19 + row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758808ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Games: 1280, Total Moves: 297110\n"
     ]
    }
   ],
   "source": [
    "# Check how many samples can be obtained\n",
    "n_games = 0\n",
    "n_moves = 0\n",
    "for game in games:\n",
    "    n_games += 1\n",
    "    moves_list = game.split(',')\n",
    "    for move in moves_list:\n",
    "        n_moves += 1\n",
    "print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46403360",
   "metadata": {},
   "source": [
    "The code below is run for baseline model only by using only the first 500 games from the dataset. You might need to create a data generator to use complete dataset. Otherwise your RAM might not enough to store all (If you run the code on free version of Google Colab, it will crash above 500 game samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9bb0ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228448,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_board():\n",
    "    return np.zeros((19, 19))  # 19x19 的空棋盤，可以是任何你認為合適的初始值\n",
    "\n",
    "# 在原始程式碼中添加此行：\n",
    "x = []\n",
    "y = []\n",
    "for game in games[:1000]:\n",
    "    board = initialize_board()\n",
    "    moves_list = game.split(',')\n",
    "    for count, move in enumerate(moves_list):\n",
    "        x.append(prepare_input(moves_list[:count], board))\n",
    "        y.append(prepare_label(moves_list[count]))\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x.shape\n",
    "y.shape\n",
    "# 其餘程式碼保持不變\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2392a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228448, 19, 19, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73521b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228448,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5510a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 02:49:09.453872: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-09 02:49:09.454017: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-09 02:49:09.466859: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "y_one_hot = tf.one_hot(y, depth=19*19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b048ff",
   "metadata": {},
   "source": [
    "Dataset splitting: 90% Training, 10% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f594acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y_one_hot.numpy(), test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c5de9",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### Simple DCNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "208834da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(19, 19, 6))\n",
    "\n",
    "    # Convolutional layers without pooling\n",
    "    conv_1 = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(inputs)\n",
    "    conv_1 = BatchNormalization()(conv_1)\n",
    "    conv_2 = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(conv_1)\n",
    "    conv_2 = BatchNormalization()(conv_2)\n",
    "    \n",
    "    conv_3 = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(conv_2)\n",
    "    conv_3 = BatchNormalization()(conv_3)\n",
    "    conv_4 = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(conv_3)\n",
    "    conv_4 = BatchNormalization()(conv_4)\n",
    "    \n",
    "    conv_5 = Conv2D(kernel_size=3, filters=16, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(conv_4)\n",
    "    conv_5 = BatchNormalization()(conv_5)\n",
    "    conv_6 = Conv2D(kernel_size=3, filters=1, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(conv_5)\n",
    "    conv_6 = BatchNormalization()(conv_6)\n",
    "    \n",
    "    conv_7 = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu',\n",
    "                     kernel_regularizer=l2(0.01))(conv_6)\n",
    "    conv_7 = BatchNormalization()(conv_7)\n",
    "    pool_1 = MaxPooling2D(pool_size=(2, 2))(conv_7)\n",
    "    \n",
    "    # Flatten after new Convolutional and Pooling layers\n",
    "    flatten = Flatten()(pool_1)\n",
    "\n",
    "    # Fully connected layers with dropout\n",
    "    dense_1 = Dense(64, activation='relu')(flatten)\n",
    "    dropout_1 = Dropout(0.02)(dense_1)\n",
    "    dense_2 = Dense(64, activation='relu')(dropout_1)\n",
    "    dropout_2 = Dropout(0.03)(dense_2)\n",
    "    dense_3 = Dense(128, activation='relu')(dropout_2)\n",
    "    dropout_3 = Dropout(0.2)(dense_3)\n",
    "    dense_4 = Dense(64, activation='relu')(dropout_3)\n",
    "    dropout_4 = Dropout(0.3)(dense_4)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(19*19, activation='softmax')(dropout_4)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    # Optimizer with learning rate scheduling\n",
    "    initial_learning_rate = 0.0002\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    "    )\n",
    "    opt = tf.keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a66e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 19, 19, 6)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 19, 19, 32)        1760      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 19, 19, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 19, 19, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 19, 19, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 19, 19, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 19, 19, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 19, 19, 16)        4624      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 19, 19, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 19, 19, 1)         145       \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 19, 19, 1)         4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 19, 19, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 19, 19, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 9, 9, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5184)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                331840    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 361)               23465     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 411790 (1.57 MB)\n",
      "Trainable params: 411372 (1.57 MB)\n",
      "Non-trainable params: 418 (1.63 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a4d7f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1607/1607 [==============================] - 53s 32ms/step - loss: 6.2468 - accuracy: 0.0122 - val_loss: 5.3064 - val_accuracy: 0.0381\n",
      "Epoch 2/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 4.9292 - accuracy: 0.0474 - val_loss: 4.4692 - val_accuracy: 0.0913\n",
      "Epoch 3/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 4.4409 - accuracy: 0.0821 - val_loss: 4.2764 - val_accuracy: 0.1380\n",
      "Epoch 4/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 4.2473 - accuracy: 0.1180 - val_loss: 4.0777 - val_accuracy: 0.1879\n",
      "Epoch 5/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 4.1296 - accuracy: 0.1542 - val_loss: 3.9736 - val_accuracy: 0.2190\n",
      "Epoch 6/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 4.0472 - accuracy: 0.1829 - val_loss: 3.9261 - val_accuracy: 0.2509\n",
      "Epoch 7/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.9812 - accuracy: 0.2102 - val_loss: 3.8651 - val_accuracy: 0.2635\n",
      "Epoch 8/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.9305 - accuracy: 0.2286 - val_loss: 3.8659 - val_accuracy: 0.2760\n",
      "Epoch 9/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.8936 - accuracy: 0.2436 - val_loss: 3.8179 - val_accuracy: 0.2977\n",
      "Epoch 10/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.8567 - accuracy: 0.2579 - val_loss: 3.7500 - val_accuracy: 0.3115\n",
      "Epoch 11/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.8289 - accuracy: 0.2672 - val_loss: 3.7434 - val_accuracy: 0.3057\n",
      "Epoch 12/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.7980 - accuracy: 0.2763 - val_loss: 3.7971 - val_accuracy: 0.2974\n",
      "Epoch 13/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.7769 - accuracy: 0.2829 - val_loss: 3.7241 - val_accuracy: 0.3170\n",
      "Epoch 14/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.7531 - accuracy: 0.2896 - val_loss: 3.6891 - val_accuracy: 0.3280\n",
      "Epoch 15/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.7367 - accuracy: 0.2943 - val_loss: 3.7539 - val_accuracy: 0.3114\n",
      "Epoch 16/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.7221 - accuracy: 0.3000 - val_loss: 3.6966 - val_accuracy: 0.3246\n",
      "Epoch 17/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.6995 - accuracy: 0.3051 - val_loss: 3.7037 - val_accuracy: 0.3162\n",
      "Epoch 18/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.6884 - accuracy: 0.3078 - val_loss: 3.6772 - val_accuracy: 0.3195\n",
      "Epoch 19/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.6780 - accuracy: 0.3120 - val_loss: 3.6906 - val_accuracy: 0.3283\n",
      "Epoch 20/20\n",
      "1607/1607 [==============================] - 52s 32ms/step - loss: 3.6651 - accuracy: 0.3139 - val_loss: 3.6442 - val_accuracy: 0.3337\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在目前儲存格或上一個儲存格中執行程式碼時，Kernel 已損毀。請檢閱儲存格中的程式碼，找出失敗的可能原因。如需詳細資訊，請按一下<a href='https://aka.ms/vscodeJupyterKernelCrash'>這裡</a>。檢視 Jupyter <a href='command:jupyter.viewOutput'>記錄</a>，以取得進一步的詳細資料。"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaddf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model_dan_tutorial.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
